word2vec
Skip Gram with Negative Sampling<br />  
The code is available in pure NumPy and also in Tensorflow<br />  
For Numpy  run train definition in ```preprocessing.py```  <br />
For Tensorflow  run ```graph.py``` <br />
Embeddings <br />
![alt text](https://github.com/pjavia/NLP/blob/master/word2vec/word_vis.gif)
Loss <br />
![alt text](https://github.com/pjavia/NLP/blob/master/word2vec/loss_vis.png)
